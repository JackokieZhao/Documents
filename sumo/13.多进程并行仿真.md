# 概述
本节介绍利用Python的`multiprocessing`模块同步进行多个场景的仿真。多进程的仿真能充分利用多核心的CPU，提高效率，特别适用于算法模型参数调校和多种流量场景的信号控制算法测试等事务。

# Python多进程
Python由于GIL的存在，在处理计算密集型任务中无法利用多线程来高效利用CPU计算资源，一个有效的解决办法是使用多进程。Python提供了一种跨平台的多进程机制，封装在`multiprocessing`模块中。我们首先简单了解一下如何使用该模块来实现并行计算。

## 计算任务：质数判断
我们从一个简单的场景——质数判断开始。要完成的计算任务是判断`CHECK_NUMBERS`以内的整数中质数的数量。其单线程版本如下。
```python
from math import sqrt
import timeit

CHECK_NUMBERS = 1000000

def check_prime(n):
    if n == 2:
        return True
    for i in range(2, int(sqrt(n) + 1)):
        if n % i == 0:
            return False
    return True

def run():
    total = 0
    for i in range(2, CHECK_NUMBERS + 1):
        if check_prime(i):
            total += 1
    return total

if __name__ == "__main__":
    import timeit
    print(run())
    print(timeit.timeit("run()", "from __main__ import run", number=1))
```

## 进程池
为了实现多进程并行计算，首先需要导入`multiprocessing`模块：
```python
import multiprocessing
```
同时，我们还需要把计算任务划分为很多子任务。这里我们只需把质数判断的区间划分为若干个子区间即可：
```python
def divide_range(lower_end, upper_end, num_range):
    '''divide a larger range into smaller ranges'''
    step = int((upper_end - lower_end) / num_range)
    ranges = []
    subrange_upper = lower_end
    while subrange_upper <= upper_end:
        subrange_lowerend = subrange_upper
        subrange_upper += step
        if subrange_upper <= upper_end:
            ranges.append((subrange_lowerend, subrange_upper))
            continue
        if subrange_lowerend < upper_end:
            ranges.append((subrange_lowerend, upper_end))
    return ranges
```
之后建立进程池，进程池的大小代表了同时处理的任务数量，通常可以指定为本机CPU的核心数量：
```python
NUM_PROCESSES = multiprocessing.cpu_count()
pool = multiprocessing.Pool(processes=NUM_PROCESSES)
```
放入进程池的任务通常定义在一个函数中，同时给出各个任务的参数列表（List）：
```python
result = pool.map(worker, params)
```
而其返回的结果`result`也是一个列表，其每一个元素都是子任务的计算结果。我们对其进行汇总即可得到最终的计算结果：
```python
total = sum(result)
```
完整的代码如下：
```python
import multiprocessing
from math import sqrt
import timeit

CHECK_NUMBERS = 1000000
NUM_PROCESSES = multiprocessing.cpu_count()

def check_prime(n):
    if n == 2:
        return True
    for i in range(2, int(sqrt(n) + 1)):
        if n % i == 0:
            return False
    return True

def worker(start, end, result_mq):
    '''count prime numbers between start and end(exclusive)'''
    start, end = sub_range
    total = 0
    for n in range(start, end):
        if check_prime(n):
            total += 1
    return total

def divide_range(lower_end, upper_end, num_range):
    '''divide a larger range into smaller ranges'''
    step = int((upper_end - lower_end) / num_range)
    ranges = []
    subrange_upper = lower_end
    while subrange_upper <= upper_end:
        subrange_lowerend = subrange_upper
        subrange_upper += step
        if subrange_upper <= upper_end:
            ranges.append((subrange_lowerend, subrange_upper))
            continue
        if subrange_lowerend < upper_end:
            ranges.append((subrange_lowerend, upper_end))
    return ranges

def run():
    params = divide_range(2, CHECK_NUMBERS + 1, 4)
    pool = multiprocessing.Pool(processes=NUM_PROCESSES)
    result = pool.map(worker, params)
    total = sum(result)
    print(total)
    return total

if __name__ == "__main__":
    import timeit
    print(timeit.timeit("run()", "from __main__ import run", number=1))
```

## 异步操作
进程池不仅有`map`方法，还有`map_async`，`apply`，`apply_async`等方法，带async后缀的方法能够实现非阻塞调用，主进程不必等到子进程运行完毕才往下运行。比如上面的run函数可以修改成如下：
```python
def run():
    params = divide_range(2, CHECK_NUMBERS + 1, 4)
    pool = multiprocessing.Pool(processes=NUM_PROCESSES)
    result = pool.map_async(worker, params)
    pool.close()
    # do something else here ...
    pool.join()
    total = sum(result.get())
    print(total)
    return total
```

# 运行多个SUMO进程
以上一节的匝道控制仿真为例，假如说我们希望能同时运行有控制和无控制的仿真场景，我们可以将子任务定义在一个函数中：
```python
def run_subprocess(params_dict):
    ...
    traci.start([sumoBinary, "-c", params_dict['filename'], "-S", "-Q"])
    while traci.simulation.getMinExpectedNumber() > 0:
    ...
        if params_dict['control_bool']:
            ...
    traci.close()
    ...
```
另外定义一个函数来实现多进程仿真：
```python
def run():
    params_dict1 = {'filename': "data/ramp_metering.sumocfg",
                    'control_bool': False}
    params_dict2 = {'filename': "data/ramp_metering2.sumocfg",
                    'control_bool': True}
    params = [params_dict1, params_dict2]
    pool = multiprocessing.Pool(processes=2)
    result = pool.map(run_subprocess, params)
    ...
```
我们将子任务的参数定义在一个Dict中，包括了仿真场景文件名和是否进行控制的bool变量。在`run()`中我们将各子任务的参数定义好，并封装在同一个列表`params`中，然后建立进程池`pool`，并把同时处理的任务数设置为2，最后用`pool.map`实现分布式处理，并将结果返回给`result`列表。

此外，在多个子任务中运行同一个仿真场景（即使用同一个SUMO配置文件）也是可以的。

由于诸多因素的限制，与单进程相比，使用两个进程仿真的耗时难以达到理想状态下的1/2，但无论如何，这种方式大大提高了多场景仿真的效率。
